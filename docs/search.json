[{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Armin Rauschenberger. Author, maintainer.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Rauschenberger (2022). transreg: Penalised regression multiple sets prior effects. R package version 0.0.1.","code":"@Manual{,   title = {transreg: Penalised regression with multiple sets of prior effects},   author = {Armin Rauschenberger},   year = {2022},   note = {R package version 0.0.1}, }"},{"path":"/index.html","id":"penalised-regression-with-multiple-sets-of-prior-coefficients","dir":"","previous_headings":"","what":"Penalised regression with multiple sets of prior coefficients","title":"Penalised regression with multiple sets of prior effects","text":"Improves predictive performance ridge lasso regression exploiting one sources prior information importance direction effects.","code":""},{"path":"/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Penalised regression with multiple sets of prior effects","text":"Install current release CRAN: latest development version GitHub:","code":"#install.packages(\"transreg\") # not yet released! #install.packages(\"remotes\") remotes::install_github(\"rauschenberger/transreg\")"},{"path":"/index.html","id":"reference","dir":"","previous_headings":"","what":"Reference","title":"Penalised regression with multiple sets of prior effects","text":"Armin Rauschenberger , Zied Landoulsi , Mark van de Wiel , Enrico Glaab  (2022). “Penalised regression multiple sets prior effects”. Manuscript preparation.","code":""},{"path":"/reference/coef.transreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Coefficients — coef.transreg","title":"Coefficients — coef.transreg","text":"Extracts coefficients","code":""},{"path":"/reference/coef.transreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Coefficients — coef.transreg","text":"","code":"# S3 method for transreg coef(object, ...)"},{"path":"/reference/coef.transreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Coefficients — coef.transreg","text":"object object class 'transreg' ... (applicable)","code":""},{"path":"/reference/coef.transreg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Coefficients — coef.transreg","text":"","code":"NA #> [1] NA"},{"path":"/reference/cv.transfer.html","id":null,"dir":"Reference","previous_headings":"","what":"Cross-validation — cv.transfer","title":"Cross-validation — cv.transfer","text":"Performs external \\(k\\)-fold cross-validation estimate predictive performance different methods","code":""},{"path":"/reference/cv.transfer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cross-validation — cv.transfer","text":"","code":"cv.transfer(   target,   source = NULL,   prior = NULL,   z = NULL,   family,   alpha,   scale = \"iso\",   sign = FALSE,   select = TRUE,   switch = TRUE,   foldid.ext = NULL,   nfolds.ext = 10,   foldid.int = NULL,   nfolds.int = 10,   type.measure = \"deviance\",   alpha.prior = NULL,   partitions = NULL,   monotone = NULL,   prs = TRUE,   diffpen = FALSE )"},{"path":"/reference/cv.transfer.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cross-validation — cv.transfer","text":"target list slot x (feature matrix n rows p columns) slot y (target vector length n) source list k lists, slot x (feature matrix m_i rows p columns) slot y (target vector length m_i) prior prior coefficients: matrix \\(p\\) rows (features) \\(k\\) columns (sources co-data) z prior weights family character \"gaussian\" (\\(y\\): real numbers), \"binomial\" (\\(y\\): 0s 1s), \"poisson\" (\\(y\\): non-negative integers); alpha elastic net mixing parameter (0=ridge, 1=lasso): number 0 1 scale character \"exp\" exponential scaling (3 parameters), \"iso\" isotonic scaling (1+\\(p\\) parameters), \"sam\" shape-constrained additive scaling sign sign discovery procedure: logical select select sources: logical switch choose positive negative weights source: logical foldid.ext external fold identifiers nfolds.ext number external folds foldid.int internal fold identifiers nfolds.int number internal folds type.measure character alpha.prior alpha source regression partitions monotone: GRridge monotone logical prs logical diffpen logical","code":""},{"path":"/reference/cv.transfer.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cross-validation — cv.transfer","text":"","code":"n <- 100; p <- 500 X <- matrix(rnorm(n=n*p),nrow=n,ncol=p) beta <- rnorm(p)*rbinom(n=p,size=1,prob=0.2) y <- X %*% beta object <- cv.transfer(target=list(y=y,x=X),prior=beta,family=\"gaussian\",alpha=0) #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 9.2e-17  #> 0.48  #> + #> Warning: cannot compute exact p-value with zeroes #> 2.8e-15  #> 1  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.13  #> + #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 1  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.8e-15  #> 0.023  #> + #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 1  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.8e-15  #> 0.53  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.16  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.84  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.98  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.75  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 8.9e-17  #> 0.43  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.8e-15  #> 0.45  #> + #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 1  #> + #> 2.7e-15  #> 0.6  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.86  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.14  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.5  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.092  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.46  #> + #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 1  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.0053  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 8.9e-17  #> 0.72  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.94  #> + #> Warning: cannot compute exact p-value with zeroes #> 2.8e-15  #> 1  #> + #> 2.7e-15  #> 0.79  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.83  #> + #> 2.8e-15  #> 0.58  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.0078  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.8e-15  #> 0.14  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.018  #> + #> Warning: cannot compute exact p-value with zeroes #> 2.8e-15  #> 1  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.96  #> + #> 9.2e-17  #> 0.6  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.98  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.47  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.8e-15  #> 0.81  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.87  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.73  #> + #> 2.7e-15  #> 0.7  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.38  #> + #> 2.8e-15  #> 0.15  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.56  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.37  #> + #> 8.9e-17  #> 0.37  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.33  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.47  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.48  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.063  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.063  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.95  #> + #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 1  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.072  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.072  #> + #> 2.7e-15  #> 0.69  #> + #> 8.9e-17  #> 0.44  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.03  #> + #> 2.8e-15  #> 0.89  #> + #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 1  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.72  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.0074  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.91  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.7  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.9e-15  #> 0.78  #> + #> 2.7e-15  #> 0.068  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.86  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 8.9e-17  #> 0.64  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.12  #> + #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 1  #> + #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 1  #> + #> 2.7e-15  #> 0.46  #> + #> 2.7e-15  #> 0.38  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.72  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.21  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.8e-15  #> 0.8  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.9  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.49  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 9.2e-17  #> 0.44  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.92  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.51  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.47  #> + #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 1  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.9e-15  #> 0.88  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.87  #> + #> Warning: cannot compute exact p-value with zeroes #> 2.8e-15  #> 1  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.8e-15  #> 0.0091  #> + #> Warning: cannot compute exact p-value with zeroes #> 3.1e-15  #> 1  #> + #> Warning: cannot compute exact p-value with zeroes #> 3.1e-15  #> 1  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 8.9e-17  #> 0.97  #> + #> 2.7e-15  #> 0.37  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.71  #> + #> 2.7e-15  #> 0.39  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.09  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.34  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.77  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.021  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.8  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.16  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.8e-15  #> 0.0028  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 8.9e-17  #> 0.84  #> + #> Warning: cannot compute exact p-value with zeroes #> 2.8e-15  #> 1  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.0098  #> + #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 1  #> + #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 1  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.99  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.67  #> + #> 2.7e-15  #> 0.084  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.8e-15  #> 0.73  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.8e-15  #> 0.64  #> + #> 2.7e-15  #> 0.27  #> +"},{"path":"/reference/dot-residuals.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate residuals — .residuals","title":"Calculate residuals — .residuals","text":"Calculates residuals observed outcome predicted values (Gaussian family) predicted probabilities (binomial family).","code":""},{"path":"/reference/dot-residuals.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate residuals — .residuals","text":"","code":".residuals(y, y_hat, family)"},{"path":"/reference/dot-residuals.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate residuals — .residuals","text":"y response: vector length \\(n\\) (see family) y_hat predicted values probabilities (see family): vector length \\(n\\), matrix \\(n\\) rows (samples) \\(k\\) columns (methods) family character \"gaussian\" (\\(y\\): real numbers, \\(y_hat\\): real numbers) \"binomial\" (\\(y\\): 0s 1s, \\(y_hat\\): unit interval)","code":""},{"path":"/reference/dot-residuals.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate residuals — .residuals","text":"","code":"n <- 100 p <- 5 X <- matrix(stats::rnorm(n*p),nrow=n,ncol=p) #y <- stats::rbinom(n,size=1,prob=0.5) y <- stats::rnorm(n) glm <- glm(y~X,family=\"gaussian\") res <- residuals.glm(glm) y_hat <- predict(glm,type=\"response\") all.equal(res,y-y_hat) #> [1] TRUE"},{"path":"/reference/dot-signdisc.html","id":null,"dir":"Reference","previous_headings":"","what":"Sign discovery — .signdisc","title":"Sign discovery — .signdisc","text":"Assigns signs prior weights obtain prior coefficients","code":""},{"path":"/reference/dot-signdisc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sign discovery — .signdisc","text":"","code":".signdisc(y, X, prior, family, foldid = NULL, nfolds = 10)"},{"path":"/reference/dot-signdisc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sign discovery — .signdisc","text":"y target: vector length \\(n\\) (see family) X features: matrix \\(n\\) rows (samples) \\(p\\) columns (features) prior prior coefficients: matrix \\(p\\) rows (features) \\(k\\) columns (sources co-data) family character \"gaussian\" (\\(y\\): real numbers), \"binomial\" (\\(y\\): 0s 1s), \"poisson\" (\\(y\\): non-negative integers); foldid fold identifiers: vector length \\(n\\) entries 1 nfolds nfolds number folds: positive integer","code":""},{"path":"/reference/dot-signdisc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sign discovery — .signdisc","text":"","code":"n <- 100; p <- 500 X <- matrix(stats::rnorm(n*p),nrow=n,ncol=p) beta <- stats::rnorm(p)*stats::rbinom(n=p,size=1,prob=0.2) y <- X %*% beta prior <- matrix(abs(beta),ncol=1) #temp <- .signdisc(y,X,prior,family=\"gaussian\") #table(sign(beta),sign(temp))"},{"path":"/reference/dot-simulate.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulation — .simulate","title":"Simulation — .simulate","text":"Simulates data","code":""},{"path":"/reference/dot-simulate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulation — .simulate","text":"","code":".simulate(   p = 1000,   n.target = 100,   n.source = 150,   k = 3,   family = \"gaussian\",   prop = 0.01,   rho.beta = 0.95,   rho.x = 0.95,   w = 0.5 )"},{"path":"/reference/dot-simulate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulation — .simulate","text":"p number features n.target sample size target data set n.source sample size(s) source data set(s), scalar vector length k k number source data sets family \"Gaussian\", \"binomial\" \"poisson\" prop approximate proportion features effects rho.beta correlation effects (across different data sets) rho.x base decreasing correlation structure correlation features w weight signal noise","code":""},{"path":"/reference/dot-simulate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulation — .simulate","text":"","code":"NA #> [1] NA"},{"path":"/reference/exp.multiple.html","id":null,"dir":"Reference","previous_headings":"","what":"Exponential scaling — exp.multiple","title":"Exponential scaling — exp.multiple","text":"Performs exponential scaling","code":""},{"path":"/reference/exp.multiple.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Exponential scaling — exp.multiple","text":"","code":"# S3 method for multiple exp(y, X, prior, family, select, plot = TRUE)"},{"path":"/reference/exp.multiple.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Exponential scaling — exp.multiple","text":"y target: vector length \\(n\\) (see family) X features: matrix \\(n\\) rows (samples) \\(p\\) columns (features) prior prior coefficients: matrix \\(p\\) rows (features) \\(k\\) columns (sources co-data) family character \"gaussian\" (\\(y\\): real numbers), \"binomial\" (\\(y\\): 0s 1s), \"poisson\" (\\(y\\): non-negative integers); select select sources: logical plot logical","code":""},{"path":"/reference/exp.multiple.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Exponential scaling — exp.multiple","text":"","code":"NA #> [1] NA"},{"path":"/reference/iso.fast.single.html","id":null,"dir":"Reference","previous_headings":"","what":"Isotonic scaling — iso.fast.single","title":"Isotonic scaling — iso.fast.single","text":"Performs isotonic scaling","code":""},{"path":"/reference/iso.fast.single.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Isotonic scaling — iso.fast.single","text":"","code":"iso.fast.single(y, X, prior, family)"},{"path":"/reference/iso.fast.single.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Isotonic scaling — iso.fast.single","text":"y target: vector length \\(n\\) (see family) X features: matrix \\(n\\) rows (samples) \\(p\\) columns (features) prior prior coefficients: matrix \\(p\\) rows (features) \\(k\\) columns (sources co-data) family character \"gaussian\" (\\(y\\): real numbers), \"binomial\" (\\(y\\): 0s 1s), \"poisson\" (\\(y\\): non-negative integers);","code":""},{"path":"/reference/iso.fast.single.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Isotonic scaling — iso.fast.single","text":"","code":"NA #> [1] NA"},{"path":"/reference/iso.multiple.html","id":null,"dir":"Reference","previous_headings":"","what":"Isotonic scaling — iso.multiple","title":"Isotonic scaling — iso.multiple","text":"Performs isotonic scaling","code":""},{"path":"/reference/iso.multiple.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Isotonic scaling — iso.multiple","text":"","code":"iso.multiple(y, X, prior, family, select = TRUE, switch = TRUE)"},{"path":"/reference/iso.multiple.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Isotonic scaling — iso.multiple","text":"y target: vector length \\(n\\) (see family) X features: matrix \\(n\\) rows (samples) \\(p\\) columns (features) prior prior coefficients: matrix \\(p\\) rows (features) \\(k\\) columns (sources co-data) family character \"gaussian\" (\\(y\\): real numbers), \"binomial\" (\\(y\\): 0s 1s), \"poisson\" (\\(y\\): non-negative integers); select select sources: logical switch choose positive negative weights source: logical","code":""},{"path":"/reference/iso.multiple.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Isotonic scaling — iso.multiple","text":"","code":"NA #> [1] NA"},{"path":"/reference/iso.single.html","id":null,"dir":"Reference","previous_headings":"","what":"Isotonic scaling — iso.single","title":"Isotonic scaling — iso.single","text":"Performs isotonic scaling. function comparison .","code":""},{"path":"/reference/iso.single.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Isotonic scaling — iso.single","text":"","code":"iso.single(y, X, prior, family)"},{"path":"/reference/iso.single.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Isotonic scaling — iso.single","text":"y target: vector length \\(n\\) X features: matrix \\(n\\) rows \\(p\\) columns prior prior coefficients: matrix \\(p\\) rows \\(k\\) columns family character \"gaussian\", \"binomial\", \"poisson\"","code":""},{"path":[]},{"path":"/reference/iso.single.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Isotonic scaling — iso.single","text":"","code":"NA #> [1] NA"},{"path":"/reference/iso.slow.single.html","id":null,"dir":"Reference","previous_headings":"","what":"Isotonic scaling — iso.slow.single","title":"Isotonic scaling — iso.slow.single","text":"Performs isotonic scaling. function comparison .","code":""},{"path":"/reference/iso.slow.single.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Isotonic scaling — iso.slow.single","text":"","code":"iso.slow.single(y, X, prior, family)"},{"path":"/reference/iso.slow.single.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Isotonic scaling — iso.slow.single","text":"y target: vector length \\(n\\) (see family) X features: matrix \\(n\\) rows (samples) \\(p\\) columns (features) prior prior coefficients: matrix \\(p\\) rows (features) \\(k\\) columns (sources co-data) family character \"gaussian\" (\\(y\\): real numbers), \"binomial\" (\\(y\\): 0s 1s), \"poisson\" (\\(y\\): non-negative integers);","code":""},{"path":[]},{"path":"/reference/iso.slow.single.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Isotonic scaling — iso.slow.single","text":"","code":"NA #> [1] NA"},{"path":"/reference/multiridge.html","id":null,"dir":"Reference","previous_headings":"","what":"multiridge wrapper — multiridge","title":"multiridge wrapper — multiridge","text":"see multiridge package.","code":""},{"path":"/reference/multiridge.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"multiridge wrapper — multiridge","text":"","code":"multiridge(X, Y, family)  # S3 method for multiridge predict(object, newx, ...)  # S3 method for multiridge coef(object, ...)"},{"path":"/reference/multiridge.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"multiridge wrapper — multiridge","text":"X list matrices n rows Y vector length n family character \"gaussian\" \"binomial\" object multiridge-object newx list matrices (new data) ... (applicable)","code":""},{"path":"/reference/multiridge.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"multiridge wrapper — multiridge","text":"Mark . van de Wiel, Mirrelijn M. van Nee Armin Rauschenberger (2021) \"Fast Cross-validation Multi-penalty High-dimensional Ridge Regression\" Journal Computational Graphical Statistics 30(4):835-847 https://doi.org/10.1080/10618600.2021.1904962","code":""},{"path":"/reference/multiridge.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"multiridge wrapper — multiridge","text":"","code":"# simulation n0 <- 100 # training samples n1 <- 10000 # testing samples n <- n0 + n1 p1 <- 5 # first covariate set p2 <- 500 # second covariate set X1 <- matrix(rnorm(n*p1),nrow=n,ncol=p1) X2 <- matrix(rnorm(n*p2),nrow=n,ncol=p2) beta1 <- rep(c(0,10),times=c(p1-4,4)) beta2 <- c(rnorm(100),rep(0,times=p2-100)) eta <- X2 %*% beta2 + X1 %*% beta1 family <- \"binomial\" if(family==\"gaussian\"){  y <- eta } else if(family==\"binomial\"){  y <- round(1/(1+exp(-eta))) } fold <- rep(c(0,1),times=c(n0,n1))  # single penalty glmnet <- glmnet::cv.glmnet(x=cbind(X1[fold==0,],X2[fold==0,]),y=y[fold==0],family=family,alpha=0) y_hat0 <- predict(glmnet,newx=cbind(X1[fold==1,],X2[fold==1,]),s=\"lambda.min\",type=\"response\")  # multiple penalties object <- multiridge(X=list(X1[fold==0,],X2[fold==0,]),Y=y[fold==0],family=family) #> [1] \"Initial penalties:\" #> [1] 100 #> [1] \"Using Brent for optimization\" #> [1] \"penalties:\" #> [1] 713.8896 #> [1] \"CV-score: -0.673\" #> [1] \"penalties:\" #> [1] 15361.38 #> [1] \"CV-score: -0.687\" #> [1] \"penalties:\" #> [1] 107.1312 #> [1] \"CV-score: -0.609\" #> [1] \"penalties:\" #> [1] 33.17659 #> [1] \"CV-score: -0.524\" #> [1] \"penalties:\" #> [1] 16.07684 #> [1] \"CV-score: -0.468\" #> [1] \"penalties:\" #> [1] 10.27419 #> [1] \"CV-score: -0.437\" #> [1] \"penalties:\" #> [1] 7.790572 #> [1] \"CV-score: -0.42\" #> [1] \"penalties:\" #> [1] 6.565911 #> [1] \"CV-score: -0.411\" #> [1] \"penalties:\" #> [1] 6.565911 #> [1] \"CV-score: -0.411\" #> [1] \"Initial penalties:\" #> [1] 100 #> [1] \"Using Brent for optimization\" #> [1] \"penalties:\" #> [1] 713.8896 #> [1] \"CV-score: -0.678\" #> [1] \"penalties:\" #> [1] 15361.38 #> [1] \"CV-score: -0.687\" #> [1] \"penalties:\" #> [1] 107.1312 #> [1] \"CV-score: -0.671\" #> [1] \"penalties:\" #> [1] 33.17659 #> [1] \"CV-score: -0.687\" #> [1] \"penalties:\" #> [1] 195.6767 #> [1] \"CV-score: -0.67\" #> [1] \"penalties:\" #> [1] 152.1897 #> [1] \"CV-score: -0.67\" #> [1] \"penalties:\" #> [1] 128.8258 #> [1] \"CV-score: -0.67\" #> [1] \"penalties:\" #> [1] 152.1897 #> [1] \"CV-score: -0.67\" #> [1] \"Initial penalties:\" #> [1]   6.565911 152.189726 #> [1] \"Using SANN for optimization\" #> [1] \"penalties:\" #> [1]   6.565911 152.189726 #> [1] \"CV-score: -0.412\" #> [1] \"penalties:\" #> [1]  11.79199 309.38732 #> [1] \"CV-score: -0.448\" #> [1] \"penalties:\" #> [1]   4.476393 316.624969 #> [1] \"CV-score: -0.388\" #> [1] \"penalties:\" #> [1]  45.39522 113.45556 #> [1] \"CV-score: -0.575\" #> [1] \"penalties:\" #> [1] 34.44014 85.39192 #> [1] \"CV-score: -0.564\" #> [1] \"penalties:\" #> [1] 13.73436 76.02054 #> [1] \"CV-score: -0.489\" #> [1] \"penalties:\" #> [1]  84.53898 110.12670 #> [1] \"CV-score: -0.613\" #> [1] \"penalties:\" #> [1]  94.43151 105.94434 #> [1] \"CV-score: -0.619\" #> [1] \"penalties:\" #> [1] 38.92035 76.04584 #> [1] \"CV-score: -0.578\" #> [1] \"penalties:\" #> [1] 119.3702 102.5202 #> [1] \"CV-score: -0.629\" #> [1] \"Initial penalties:\" #> [1]   4.476393 316.624969 #> [1] \"Using Nelder-Mead for optimization\" #> [1] \"penalties:\" #> [1]   4.476393 316.624969 #> [1] \"CV-score: -0.388\" #> [1] \"penalties:\" #> [1]   4.947179 316.624969 #> [1] \"CV-score: -0.393\" #> [1] \"penalties:\" #> [1]   4.476393 349.924708 #> [1] \"CV-score: -0.388\" #> [1] \"penalties:\" #> [1]   4.050408 349.924708 #> [1] \"CV-score: -0.383\" #> [1] \"penalties:\" #> [1]   3.664961 367.865732 #> [1] \"CV-score: -0.379\" #> [1] \"penalties:\" #> [1]   3.664961 332.858679 #> [1] \"CV-score: -0.379\" #> [1] \"penalties:\" #> [1]   3.316194 324.640369 #> [1] \"CV-score: -0.375\" #> [1] \"penalties:\" #> [1]   2.71507 377.17830 #> [1] \"CV-score: -0.368\" #> [1] \"penalties:\" #> [1]   2.114498 411.668335 #> [1] \"CV-score: -0.362\" #> [1] \"penalties:\" #> [1]   1.913277 363.296030 #> [1] \"CV-score: -0.358\" #> [1] \"penalties:\" #> [1]   1.382395 361.032511 #> [1] \"CV-score: -0.352\" #> [1] \"penalties:\" #> [1]   0.8814541 457.8163000 #> [1] \"CV-score: -0.349\" #> [1] \"penalties:\" #> [1]   0.4544432 543.6703081 #> [1] \"CV-score: -0.348\" #> [1] \"penalties:\" #> [1]   0.2971012 476.7980433 #> [1] \"CV-score: -0.347\" #> [1] \"penalties:\" #> [1]   0.1113661 513.1306606 #> [1] \"CV-score: -0.351\" #> [1] \"penalties:\" #> [1]   0.09766789 717.99888194 #> [1] \"CV-score: -0.353\" #> [1] \"penalties:\" #> [1]   0.7127088 428.7367147 #> [1] \"CV-score: -0.347\" #> [1] \"penalties:\" #> [1]   0.4659475 376.0014545 #> [1] \"CV-score: -0.345\" #> [1] \"penalties:\" #> [1]   0.4718084 312.6917909 #> [1] \"CV-score: -0.344\" #> [1] \"penalties:\" #> [1]   1.131809 281.172402 #> [1] \"CV-score: -0.347\" #> [1] \"penalties:\" #> [1]   0.4150703 417.8246145 #> [1] \"CV-score: -0.346\" #> [1] \"penalties:\" #> [1]   0.2747737 304.7332372 #> [1] \"CV-score: -0.344\" #> [1] \"penalties:\" #> [1]   0.348706 331.884934 #> [1] \"CV-score: -0.344\" #> [1] \"penalties:\" #> [1]   0.3123339 228.0564103 #> [1] \"CV-score: -0.342\" #> [1] \"penalties:\" #> [1]   0.2709367 168.4870070 #> [1] \"CV-score: -0.34\" #> [1] \"penalties:\" #> [1]   0.46522 172.88729 #> [1] \"CV-score: -0.339\" #> [1] \"penalties:\" #> [1]   0.6053408 130.2220994 #> [1] \"CV-score: -0.336\" y_hat1 <- predict(object,newx=list(X1[fold==1,],X2[fold==1,]))  # comparison if(family==\"gaussian\"){ loss0 <- mean((y[fold==1]-y_hat0)^2) loss1 <- mean((y[fold==1]-y_hat1)^2) } else if(family==\"binomial\"){ loss0 <- mean(y[fold==1]!=round(y_hat0)) loss1 <- mean(y[fold==1]!=round(y_hat1)) } loss0 #> [1] 0.4051 loss1 #> [1] 0.175  # equivalence beta <- coef(object) eta2 <- beta[[1]] + X1[fold==1,] %*% beta[[2]] + X2[fold==1,] %*% beta[[3]] if(family==\"gaussian\"){ y_hat2 <- eta2 } else if(family==\"binomial\"){ y_hat2 <- 1/(1 + exp(-eta2)) } all.equal(y_hat1,y_hat2) #> [1] TRUE"},{"path":"/reference/predict.transreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Predict — predict.transreg","title":"Predict — predict.transreg","text":"Predicts outcome","code":""},{"path":"/reference/predict.transreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predict — predict.transreg","text":"","code":"# S3 method for transreg predict(object, newx, ...)"},{"path":"/reference/predict.transreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predict — predict.transreg","text":"object object class 'transreg' newx features: matrix m rows (samples) p columns (variables) ... (applicable)","code":""},{"path":"/reference/predict.transreg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Predict — predict.transreg","text":"","code":"NA #> [1] NA"},{"path":"/reference/residuals.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate residuals — residuals","title":"Calculate residuals — residuals","text":"Calculates residuals observed outcome predicted values (Gaussian family) predicted probabilities (binomial family).","code":""},{"path":"/reference/residuals.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate residuals — residuals","text":"","code":"residuals(y, y_hat, family)"},{"path":"/reference/residuals.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate residuals — residuals","text":"y response: vector length \\(n\\) (see family) y_hat predicted values probabilities (see family): vector length \\(n\\), matrix \\(n\\) rows (samples) \\(k\\) columns (methods) family character \"gaussian\" (\\(y\\): real numbers, \\(y_hat\\): real numbers) \"binomial\" (\\(y\\): 0s 1s, \\(y_hat\\): unit interval)","code":""},{"path":"/reference/residuals.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate residuals — residuals","text":"","code":"n <- 100 p <- 5 X <- matrix(stats::rnorm(n*p),nrow=n,ncol=p) #y <- stats::rbinom(n,size=1,prob=0.5) y <- stats::rnorm(n) glm <- glm(y~X,family=\"gaussian\") res <- residuals.glm(glm) y_hat <- predict(glm,type=\"response\") all.equal(res,y-y_hat) #> [1] TRUE"},{"path":"/reference/sign.disc.html","id":null,"dir":"Reference","previous_headings":"","what":"Sign discovery — sign.disc","title":"Sign discovery — sign.disc","text":"Assigns signs prior weights obtain prior coefficients","code":""},{"path":"/reference/sign.disc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sign discovery — sign.disc","text":"","code":"# S3 method for disc sign(y, X, prior, family, foldid = NULL, nfolds = 10)"},{"path":"/reference/sign.disc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sign discovery — sign.disc","text":"y target: vector length \\(n\\) (see family) X features: matrix \\(n\\) rows (samples) \\(p\\) columns (features) prior prior coefficients: matrix \\(p\\) rows (features) \\(k\\) columns (sources co-data) family character \"gaussian\" (\\(y\\): real numbers), \"binomial\" (\\(y\\): 0s 1s), \"poisson\" (\\(y\\): non-negative integers); foldid fold identifiers: vector length \\(n\\) entries 1 nfolds nfolds number folds: positive integer","code":""},{"path":"/reference/sign.disc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sign discovery — sign.disc","text":"","code":"n <- 100; p <- 500 X <- matrix(stats::rnorm(n*p),nrow=n,ncol=p) beta <- stats::rnorm(p)*stats::rbinom(n=p,size=1,prob=0.2) y <- X %*% beta prior <- matrix(abs(beta),ncol=1) #temp <- sign.disc(y,X,prior,family=\"gaussian\") #table(sign(beta),sign(temp))"},{"path":"/reference/transreg-package.html","id":null,"dir":"Reference","previous_headings":"","what":"Penalised regression with multiple sets of prior effects — transreg-package","title":"Penalised regression with multiple sets of prior effects — transreg-package","text":"R package starnet implements penalised regression multiple sets prior effects.","code":""},{"path":"/reference/transreg-package.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Penalised regression with multiple sets of prior effects — transreg-package","text":"Use function transreg model fitting. Type library(transreg) ?transreg help(\"transreg)\" open help file. See vignette examples. Type vignette(\"transreg\") browseVignettes(\"transreg\") open vignette.","code":""},{"path":"/reference/transreg-package.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Penalised regression with multiple sets of prior effects — transreg-package","text":"Armin Rauschenberger, Zied Landoulsi, Mark van de Wiel, Enrico Glaab (2022). \"Penalised regression multiple sets prior effects\". Manuscript preparation. armin.rauschenberger@uni.lu","code":""},{"path":"/reference/transreg-package.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Penalised regression with multiple sets of prior effects — transreg-package","text":"","code":"NA #> [1] NA"},{"path":"/reference/transreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Penalised regression with multiple sets of prior effects — transreg","title":"Penalised regression with multiple sets of prior effects — transreg","text":"Implements penalised regression multiple sets prior effects","code":""},{"path":"/reference/transreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Penalised regression with multiple sets of prior effects — transreg","text":"","code":"transreg(   y,   X,   prior,   family = \"gaussian\",   alpha = 1,   foldid = NULL,   nfolds = 10,   scale = \"iso\",   sign = FALSE,   switch = TRUE,   select = TRUE,   diffpen = FALSE )"},{"path":"/reference/transreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Penalised regression with multiple sets of prior effects — transreg","text":"y target: vector length \\(n\\) (see family) X features: matrix \\(n\\) rows (samples) \\(p\\) columns (features) prior prior coefficients: matrix \\(p\\) rows (features) \\(k\\) columns (sources co-data) family character \"gaussian\" (\\(y\\): real numbers), \"binomial\" (\\(y\\): 0s 1s), \"poisson\" (\\(y\\): non-negative integers); alpha elastic net mixing parameter (0=ridge, 1=lasso): number 0 1 foldid fold identifiers: vector length \\(n\\) entries 1 nfolds nfolds number folds: positive integer scale character \"exp\" exponential scaling (3 parameters), \"iso\" isotonic scaling (1+\\(p\\) parameters), \"sam\" shape-constrained additive scaling sign sign discovery procedure: logical switch choose positive negative weights source: logical select select sources: logical diffpen differential penalisation features meta-features: logical","code":""},{"path":"/reference/transreg.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Penalised regression with multiple sets of prior effects — transreg","text":"\\(n\\): sample size \\(p\\): number features \\(k\\): number sources","code":""},{"path":[]},{"path":"/reference/transreg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Penalised regression with multiple sets of prior effects — transreg","text":"","code":"n <- 100; p <- 500 X <- matrix(rnorm(n=n*p),nrow=n,ncol=p) beta <- rnorm(p)*rbinom(n=p,size=1,prob=0.2) prior <- beta # plus noise y <- X %*% beta prior <- ifelse(beta<(-1),0,ifelse(beta>1,beta,0)) plot(x=beta,y=prior)  object <- transreg(y=y,X=X,prior=prior) #> Warning: Consider sign discovery procedure. #> 0.0048  #> 0.094  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 0.0041  #> 0.49  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 0.011  #> 0.016  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 0.0071  #> 0.003  #> - #> 0.0056  #> 0.38  #> + #> Warning: cannot compute exact p-value with zeroes #> 0.0031  #> 1  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 0.013  #> 0.33  #> + #> 0.012  #> 0.9  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 0.0036  #> 0.65  #> + #> Warning: cannot compute exact p-value with zeroes #> 0.0059  #> 1  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 0.0031  #> 0.00024  #> -"},{"path":"/news/index.html","id":"transreg-001-2022-08-04","dir":"Changelog","previous_headings":"","what":"transreg 0.0.1 (2022-08-04)","title":"transreg 0.0.1 (2022-08-04)","text":"first public commit","code":""}]

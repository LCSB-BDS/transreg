[{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Armin Rauschenberger. Author, maintainer.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Rauschenberger (2022). transreg: Penalised regression multiple sets prior effects. R package version 0.0.1.","code":"@Manual{,   title = {transreg: Penalised regression with multiple sets of prior effects},   author = {Armin Rauschenberger},   year = {2022},   note = {R package version 0.0.1}, }"},{"path":"/index.html","id":"penalised-regression-with-multiple-sets-of-prior-coefficients","dir":"","previous_headings":"","what":"Penalised regression with multiple sets of prior coefficients","title":"Penalised regression with multiple sets of prior effects","text":"Improves predictive performance ridge lasso regression exploiting one sources prior information importance direction effects.","code":""},{"path":"/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Penalised regression with multiple sets of prior effects","text":"Install current release CRAN: latest development version GitHub:","code":"#install.packages(\"transreg\") # not yet released! #install.packages(\"remotes\") remotes::install_github(\"rauschenberger/transreg\")"},{"path":"/index.html","id":"reference","dir":"","previous_headings":"","what":"Reference","title":"Penalised regression with multiple sets of prior effects","text":"Armin Rauschenberger , Zied Landoulsi , Mark van de Wiel , Enrico Glaab  (2022). “Penalised regression multiple sets prior effects”. Manuscript preparation.","code":""},{"path":"/reference/cv.transfer.html","id":null,"dir":"Reference","previous_headings":"","what":"Cross-validation — cv.transfer","title":"Cross-validation — cv.transfer","text":"Performs external \\(k\\)-fold cross-validation estimate predictive performance different methods","code":""},{"path":"/reference/cv.transfer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cross-validation — cv.transfer","text":"","code":"cv.transfer(   target,   source = NULL,   prior = NULL,   z = NULL,   family,   alpha,   scale = \"iso\",   sign = FALSE,   select = TRUE,   switch = TRUE,   foldid.ext = NULL,   nfolds.ext = 10,   foldid.int = NULL,   nfolds.int = 10,   type.measure = \"deviance\",   alpha.prior = NULL,   partitions = NULL,   monotone = NULL,   prs = TRUE,   diffpen = FALSE )"},{"path":"/reference/cv.transfer.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cross-validation — cv.transfer","text":"target list slot x (feature matrix n rows p columns) slot y (target vector length n) source list k lists, slot x (feature matrix m_i rows p columns) slot y (target vector length m_i) prior prior coefficients: matrix \\(p\\) rows (features) \\(k\\) columns (sources co-data) z prior weights family character \"gaussian\" (\\(y\\): real numbers), \"binomial\" (\\(y\\): 0s 1s), \"poisson\" (\\(y\\): non-negative integers); alpha elastic net mixing parameter (0=ridge, 1=lasso): number 0 1 scale character \"exp\" exponential scaling (3 parameters), \"iso\" isotonic scaling (1+\\(p\\) parameters), \"sam\" shape-constrained additive scaling sign sign discovery procedure: logical select select sources: logical switch choose positive negative weights source: logical foldid.ext external fold identifiers nfolds.ext number external folds foldid.int internal fold identifiers nfolds.int number internal folds type.measure character alpha.prior alpha source regression partitions monotone: GRridge monotone logical prs logical diffpen logical","code":""},{"path":"/reference/cv.transfer.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cross-validation — cv.transfer","text":"","code":"n <- 100; p <- 500 X <- matrix(rnorm(n=n*p),nrow=n,ncol=p) beta <- rnorm(p)*rbinom(n=p,size=1,prob=0.2) y <- X %*% beta object <- cv.transfer(target=list(y=y,x=X),prior=beta,family=\"gaussian\",alpha=0) #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 8.9e-17  #> 0.037  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.8e-15  #> 0.48  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.029  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.9e-15  #> 0.34  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.87  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.71  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.0099  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.15  #> + #> Warning: cannot compute exact p-value with zeroes #> 2.8e-15  #> 1  #> + #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 1  #> + #> Warning: cannot compute exact p-value with zeroes #> 2.8e-15  #> 1  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 8.9e-17  #> 0.81  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.21  #> + #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 1  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.25  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.8e-15  #> 0.95  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.8e-15  #> 0.12  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.8e-15  #> 0.27  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.28  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.47  #> + #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 1  #> + #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 1  #> + #> 9.2e-17  #> 0.81  #> + #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 1  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.11  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.8e-15  #> 0.5  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.69  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.2  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.8e-15  #> 0.83  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.73  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.54  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.8e-15  #> 0.017  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.8e-15  #> 0.1  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 9.2e-17  #> 0.3  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.9  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.9e-15  #> 0.47  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.8e-15  #> 0.67  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.8e-15  #> 0.42  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.16  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.8e-15  #> 0.06  #> + #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 1  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.013  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.8e-15  #> 0.79  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.8e-15  #> 0.99  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 1e-16  #> 0.21  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.8e-15  #> 0.86  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.9e-15  #> 0.071  #> + #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 1  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.85  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.9e-15  #> 0.12  #> + #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 1  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.8e-15  #> 0.28  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.17  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.8e-15  #> 0.98  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.8e-15  #> 0.14  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 8.9e-17  #> 0.84  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.8e-15  #> 0.43  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.8e-15  #> 0.56  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.92  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.65  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.8e-15  #> 0.65  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.48  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.53  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.35  #> + #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 1  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.8e-15  #> 0.69  #> + #> 8.9e-17  #> 0.07  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.38  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.9e-15  #> 0.84  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.41  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.48  #> + #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 1  #> + #> 2.8e-15  #> 0.077  #> + #> 2.8e-15  #> 0.023  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.8e-15  #> 0.35  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.8e-15  #> 0.67  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.8e-15  #> 0.17  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 8.9e-17  #> 0.93  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.68  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.47  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.8e-15  #> 0.26  #> + #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 1  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.8e-15  #> 0.21  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.99  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 1  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.56  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.92  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.66  #> + #> Warning: cannot compute exact p-value with zeroes #> 9.2e-17  #> 1  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.82  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.99  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.8e-15  #> 0.4  #> + #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 1  #> + #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 1  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.8e-15  #> 0.27  #> + #> 2.7e-15  #> 0.3  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.8e-15  #> 0.83  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.9e-15  #> 0.34  #> + #> Warning: cannot compute exact p-value with zeroes #> 2.8e-15  #> 1  #> + #> Warning: cannot compute exact p-value with zeroes #> 9.5e-17  #> 1  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.8e-15  #> 0.048  #> + #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 1  #> + #> Warning: cannot compute exact p-value with zeroes #> 2.9e-15  #> 1  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.8e-15  #> 0.053  #> + #> Warning: cannot compute exact p-value with zeroes #> 2.8e-15  #> 1  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.2  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.8e-15  #> 0.27  #> + #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 1  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.7e-15  #> 0.53  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.8e-15  #> 0.36  #> +"},{"path":"/reference/dot-simulate.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulation — .simulate","title":"Simulation — .simulate","text":"Simulates data","code":""},{"path":"/reference/dot-simulate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulation — .simulate","text":"","code":".simulate(   p = 1000,   n.target = 100,   n.source = 150,   k = 3,   family = \"gaussian\",   prop = 0.01,   rho.beta = 0.95,   rho.x = 0.95,   w = 0.5 )"},{"path":"/reference/dot-simulate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulation — .simulate","text":"p number features n.target sample size target data set n.source sample size(s) source data set(s), scalar vector length k k number source data sets family \"Gaussian\", \"binomial\" \"poisson\" prop approximate proportion features effects rho.beta correlation effects (across different data sets) rho.x base decreasing correlation structure correlation features w weight signal noise","code":""},{"path":"/reference/dot-simulate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulation — .simulate","text":"","code":"NA #> [1] NA"},{"path":"/reference/exp.multiple.html","id":null,"dir":"Reference","previous_headings":"","what":"Exponential scaling — exp.multiple","title":"Exponential scaling — exp.multiple","text":"Performs exponential scaling","code":""},{"path":"/reference/exp.multiple.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Exponential scaling — exp.multiple","text":"","code":"# S3 method for multiple exp(y, X, prior, family, select, plot = TRUE)"},{"path":"/reference/exp.multiple.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Exponential scaling — exp.multiple","text":"y target: vector length \\(n\\) (see family) X features: matrix \\(n\\) rows (samples) \\(p\\) columns (features) prior prior coefficients: matrix \\(p\\) rows (features) \\(k\\) columns (sources co-data) family character \"gaussian\" (\\(y\\): real numbers), \"binomial\" (\\(y\\): 0s 1s), \"poisson\" (\\(y\\): non-negative integers); select select sources: logical plot logical","code":""},{"path":"/reference/exp.multiple.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Exponential scaling — exp.multiple","text":"","code":"NA #> [1] NA"},{"path":"/reference/iso.fast.single.html","id":null,"dir":"Reference","previous_headings":"","what":"Isotonic scaling — iso.fast.single","title":"Isotonic scaling — iso.fast.single","text":"Performs isotonic scaling","code":""},{"path":"/reference/iso.fast.single.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Isotonic scaling — iso.fast.single","text":"","code":"iso.fast.single(y, X, prior, family)"},{"path":"/reference/iso.fast.single.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Isotonic scaling — iso.fast.single","text":"y target: vector length \\(n\\) (see family) X features: matrix \\(n\\) rows (samples) \\(p\\) columns (features) prior prior coefficients: matrix \\(p\\) rows (features) \\(k\\) columns (sources co-data) family character \"gaussian\" (\\(y\\): real numbers), \"binomial\" (\\(y\\): 0s 1s), \"poisson\" (\\(y\\): non-negative integers);","code":""},{"path":"/reference/iso.fast.single.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Isotonic scaling — iso.fast.single","text":"","code":"NA #> [1] NA"},{"path":"/reference/iso.multiple.html","id":null,"dir":"Reference","previous_headings":"","what":"Isotonic scaling — iso.multiple","title":"Isotonic scaling — iso.multiple","text":"Performs isotonic scaling","code":""},{"path":"/reference/iso.multiple.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Isotonic scaling — iso.multiple","text":"","code":"iso.multiple(y, X, prior, family, select = TRUE, switch = TRUE)"},{"path":"/reference/iso.multiple.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Isotonic scaling — iso.multiple","text":"y target: vector length \\(n\\) (see family) X features: matrix \\(n\\) rows (samples) \\(p\\) columns (features) prior prior coefficients: matrix \\(p\\) rows (features) \\(k\\) columns (sources co-data) family character \"gaussian\" (\\(y\\): real numbers), \"binomial\" (\\(y\\): 0s 1s), \"poisson\" (\\(y\\): non-negative integers); select select sources: logical switch choose positive negative weights source: logical","code":""},{"path":"/reference/iso.multiple.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Isotonic scaling — iso.multiple","text":"","code":"NA #> [1] NA"},{"path":"/reference/iso.single.html","id":null,"dir":"Reference","previous_headings":"","what":"Isotonic scaling — iso.single","title":"Isotonic scaling — iso.single","text":"Performs isotonic scaling. function comparison .","code":""},{"path":"/reference/iso.single.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Isotonic scaling — iso.single","text":"","code":"iso.single(y, X, prior, family)"},{"path":"/reference/iso.single.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Isotonic scaling — iso.single","text":"y target: vector length \\(n\\) X features: matrix \\(n\\) rows \\(p\\) columns prior prior coefficients: matrix \\(p\\) rows \\(k\\) columns family character \"gaussian\", \"binomial\", \"poisson\"","code":""},{"path":[]},{"path":"/reference/iso.single.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Isotonic scaling — iso.single","text":"","code":"NA #> [1] NA"},{"path":"/reference/iso.slow.single.html","id":null,"dir":"Reference","previous_headings":"","what":"Isotonic scaling — iso.slow.single","title":"Isotonic scaling — iso.slow.single","text":"Performs isotonic scaling. function comparison .","code":""},{"path":"/reference/iso.slow.single.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Isotonic scaling — iso.slow.single","text":"","code":"iso.slow.single(y, X, prior, family)"},{"path":"/reference/iso.slow.single.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Isotonic scaling — iso.slow.single","text":"y target: vector length \\(n\\) (see family) X features: matrix \\(n\\) rows (samples) \\(p\\) columns (features) prior prior coefficients: matrix \\(p\\) rows (features) \\(k\\) columns (sources co-data) family character \"gaussian\" (\\(y\\): real numbers), \"binomial\" (\\(y\\): 0s 1s), \"poisson\" (\\(y\\): non-negative integers);","code":""},{"path":[]},{"path":"/reference/iso.slow.single.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Isotonic scaling — iso.slow.single","text":"","code":"NA #> [1] NA"},{"path":"/reference/multiridge.html","id":null,"dir":"Reference","previous_headings":"","what":"multiridge wrapper — multiridge","title":"multiridge wrapper — multiridge","text":"see multiridge package.","code":""},{"path":"/reference/multiridge.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"multiridge wrapper — multiridge","text":"","code":"multiridge(X, Y, family)  # S3 method for multiridge predict(object, newx, ...)  # S3 method for multiridge coef(object, ...)"},{"path":"/reference/multiridge.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"multiridge wrapper — multiridge","text":"X list matrices n rows Y vector length n family character \"gaussian\" \"binomial\" object multiridge-object newx list matrices (new data) ... (applicable)","code":""},{"path":"/reference/multiridge.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"multiridge wrapper — multiridge","text":"Mark . van de Wiel, Mirrelijn M. van Nee Armin Rauschenberger (2021) \"Fast Cross-validation Multi-penalty High-dimensional Ridge Regression\" Journal Computational Graphical Statistics 30(4):835-847 https://doi.org/10.1080/10618600.2021.1904962","code":""},{"path":"/reference/multiridge.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"multiridge wrapper — multiridge","text":"","code":"# simulation n0 <- 100 # training samples n1 <- 10000 # testing samples n <- n0 + n1 p1 <- 5 # first covariate set p2 <- 500 # second covariate set X1 <- matrix(rnorm(n*p1),nrow=n,ncol=p1) X2 <- matrix(rnorm(n*p2),nrow=n,ncol=p2) beta1 <- rep(c(0,10),times=c(p1-4,4)) beta2 <- c(rnorm(100),rep(0,times=p2-100)) eta <- X2 %*% beta2 + X1 %*% beta1 family <- \"binomial\" if(family==\"gaussian\"){  y <- eta } else if(family==\"binomial\"){  y <- round(1/(1+exp(-eta))) } fold <- rep(c(0,1),times=c(n0,n1))  # single penalty glmnet <- glmnet::cv.glmnet(x=cbind(X1[fold==0,],X2[fold==0,]),y=y[fold==0],family=family,alpha=0) y_hat0 <- predict(glmnet,newx=cbind(X1[fold==1,],X2[fold==1,]),s=\"lambda.min\",type=\"response\")  # multiple penalties object <- multiridge(X=list(X1[fold==0,],X2[fold==0,]),Y=y[fold==0],family=family) #> [1] \"Initial penalties:\" #> [1] 100 #> [1] \"Using Brent for optimization\" #> [1] \"penalties:\" #> [1] 713.8896 #> [1] \"CV-score: -0.674\" #> [1] \"penalties:\" #> [1] 15361.38 #> [1] \"CV-score: -0.692\" #> [1] \"penalties:\" #> [1] 107.1312 #> [1] \"CV-score: -0.594\" #> [1] \"penalties:\" #> [1] 33.17659 #> [1] \"CV-score: -0.495\" #> [1] \"penalties:\" #> [1] 16.07684 #> [1] \"CV-score: -0.432\" #> [1] \"penalties:\" #> [1] 10.27419 #> [1] \"CV-score: -0.398\" #> [1] \"penalties:\" #> [1] 7.790572 #> [1] \"CV-score: -0.379\" #> [1] \"penalties:\" #> [1] 6.565911 #> [1] \"CV-score: -0.368\" #> [1] \"penalties:\" #> [1] 6.565911 #> [1] \"CV-score: -0.368\" #> [1] \"Initial penalties:\" #> [1] 100 #> [1] \"Using Brent for optimization\" #> [1] \"penalties:\" #> [1] 713.8896 #> [1] \"CV-score: -0.699\" #> [1] \"penalties:\" #> [1] 15361.38 #> [1] \"CV-score: -0.693\" #> [1] \"penalties:\" #> [1] 102363.6 #> [1] \"CV-score: -0.693\" #> [1] \"penalties:\" #> [1] 45817.4 #> [1] \"CV-score: -0.693\" #> [1] \"penalties:\" #> [1] 120928.3 #> [1] \"CV-score: -0.693\" #> [1] \"penalties:\" #> [1] 366407.5 #> [1] \"CV-score: -0.693\" #> [1] \"penalties:\" #> [1] 465318.3 #> [1] \"CV-score: -0.693\" #> [1] \"penalties:\" #> [1] 778745.7 #> [1] \"CV-score: -0.693\" #> [1] \"penalties:\" #> [1] 1158436 #> [1] \"CV-score: -0.693\" #> [1] \"penalties:\" #> [1] 1480704 #> [1] \"CV-score: -0.693\" #> [1] \"penalties:\" #> [1] 1749246 #> [1] \"CV-score: -0.693\" #> [1] \"penalties:\" #> [1] 1749246 #> [1] \"CV-score: -0.693\" #> [1] \"Initial penalties:\" #> [1] 6.565911e+00 1.000000e+06 #> [1] \"Using SANN for optimization\" #> [1] \"penalties:\" #> [1] 6.565911e+00 1.000000e+06 #> [1] \"CV-score: -0.368\" #> [1] \"penalties:\" #> [1] 1.179199e+01 2.032905e+06 #> [1] \"CV-score: -0.408\" #> [1] \"penalties:\" #> [1] 4.476393e+00 2.080462e+06 #> [1] \"CV-score: -0.347\" #> [1] \"penalties:\" #> [1]     45.39522 745487.61181 #> [1] \"CV-score: -0.524\" #> [1] \"penalties:\" #> [1]     34.44014 561088.56888 #> [1] \"CV-score: -0.499\" #> [1] \"penalties:\" #> [1]     13.73436 499511.67055 #> [1] \"CV-score: -0.42\" #> [1] \"penalties:\" #> [1]     84.53898 723614.52779 #> [1] \"CV-score: -0.576\" #> [1] \"penalties:\" #> [1]     94.43151 696133.31588 #> [1] \"CV-score: -0.585\" #> [1] \"penalties:\" #> [1]     38.92035 499677.85181 #> [1] \"CV-score: -0.51\" #> [1] \"penalties:\" #> [1]    119.3702 673634.2426 #> [1] \"CV-score: -0.602\" #> [1] \"Initial penalties:\" #> [1] 4.476393e+00 2.080462e+06 #> [1] \"Using Nelder-Mead for optimization\" #> [1] \"penalties:\" #> [1] 4.476393e+00 2.080462e+06 #> [1] \"CV-score: -0.347\" #> [1] \"penalties:\" #> [1] 4.947179e+00 2.080462e+06 #> [1] \"CV-score: -0.352\" #> [1] \"penalties:\" #> [1] 4.476393e+00 2.299266e+06 #> [1] \"CV-score: -0.347\" #> [1] \"penalties:\" #> [1] 4.050408e+00 2.299266e+06 #> [1] \"CV-score: -0.342\" #> [1] \"penalties:\" #> [1] 3.664961e+00 2.417152e+06 #> [1] \"CV-score: -0.337\" #> [1] \"penalties:\" #> [1] 3.664961e+00 2.671366e+06 #> [1] \"CV-score: -0.337\" #> [1] \"penalties:\" #> [1] 3.316194e+00 3.027055e+06 #> [1] \"CV-score: -0.333\" #> [1] \"penalties:\" #> [1] 2.715070e+00 3.182255e+06 #> [1] \"CV-score: -0.325\" #> [1] \"penalties:\" #> [1] 2.114498e+00 3.743759e+06 #> [1] \"CV-score: -0.317\" #> [1] \"penalties:\" #> [1] 1.913277e+00 4.688394e+06 #> [1] \"CV-score: -0.314\" #> [1] \"penalties:\" #> [1] 1.382395e+00 6.529563e+06 #> [1] \"CV-score: -0.306\" #> [1] \"penalties:\" #> [1] 8.814541e-01 8.075543e+06 #> [1] \"CV-score: -0.299\" #> [1] \"penalties:\" #> [1] 4.544432e-01 1.319008e+07 #> [1] \"CV-score: -0.296\" #> [1] \"penalties:\" #> [1] 2.971012e-01 2.300508e+07 #> [1] \"CV-score: -0.297\" #> [1] \"penalties:\" #> [1] 4.852663e-01 1.461150e+07 #> [1] \"CV-score: -0.296\" #> [1] \"penalties:\" #> [1] 1.595246e-01 2.951604e+07 #> [1] \"CV-score: -0.302\" #> [1] \"penalties:\" #> [1] 2.737025e-01 2.024252e+07 #> [1] \"CV-score: -0.298\" #> [1] \"penalties:\" #> [1] 8.057142e-01 9.520892e+06 #> [1] \"CV-score: -0.298\" #> [1] \"penalties:\" #> [1] 3.585125e-01 1.676362e+07 #> [1] \"CV-score: -0.296\" #> [1] \"penalties:\" #> [1] 6.151138e-01 1.149673e+07 #> [1] \"CV-score: -0.296\" #> [1] \"penalties:\" #> [1] 4.103147e-01 1.525526e+07 #> [1] \"CV-score: -0.296\" #> [1] \"penalties:\" #> [1] 5.374557e-01 1.263347e+07 #> [1] \"CV-score: -0.296\" #> [1] \"penalties:\" #> [1] 4.389585e-01 1.455276e+07 #> [1] \"CV-score: -0.296\" y_hat1 <- predict(object,newx=list(X1[fold==1,],X2[fold==1,]))  # comparison if(family==\"gaussian\"){ loss0 <- mean((y[fold==1]-y_hat0)^2) loss1 <- mean((y[fold==1]-y_hat1)^2) } else if(family==\"binomial\"){ loss0 <- mean(y[fold==1]!=round(y_hat0)) loss1 <- mean(y[fold==1]!=round(y_hat1)) } loss0 #> [1] 0.3942 loss1 #> [1] 0.1662  # equivalence beta <- coef(object) eta2 <- beta[[1]] + X1[fold==1,] %*% beta[[2]] + X2[fold==1,] %*% beta[[3]] if(family==\"gaussian\"){ y_hat2 <- eta2 } else if(family==\"binomial\"){ y_hat2 <- 1/(1 + exp(-eta2)) } all.equal(y_hat1,y_hat2) #> [1] TRUE"},{"path":"/reference/predict.transreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Predict — predict.transreg","title":"Predict — predict.transreg","text":"Predicts outcome","code":""},{"path":"/reference/predict.transreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predict — predict.transreg","text":"","code":"# S3 method for transreg predict(object, newx, ...)"},{"path":"/reference/predict.transreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predict — predict.transreg","text":"object object class 'transreg' newx features: matrix m rows (samples) p columns (variables) ... (applicable)","code":""},{"path":"/reference/predict.transreg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Predict — predict.transreg","text":"","code":"NA #> [1] NA"},{"path":"/reference/residuals.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate residuals — residuals","title":"Calculate residuals — residuals","text":"Calculates residuals observed outcome predicted values (Gaussian family) predicted probabilities (binomial family).","code":""},{"path":"/reference/residuals.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate residuals — residuals","text":"","code":"residuals(y, y_hat, family)"},{"path":"/reference/residuals.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate residuals — residuals","text":"y response: vector length \\(n\\) (see family) y_hat predicted values probabilities (see family): vector length \\(n\\), matrix \\(n\\) rows (samples) \\(k\\) columns (methods) family character \"gaussian\" (\\(y\\): real numbers, \\(y_hat\\): real numbers) \"binomial\" (\\(y\\): 0s 1s, \\(y_hat\\): unit interval)","code":""},{"path":"/reference/residuals.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate residuals — residuals","text":"","code":"n <- 100 p <- 5 X <- matrix(stats::rnorm(n*p),nrow=n,ncol=p) #y <- stats::rbinom(n,size=1,prob=0.5) y <- stats::rnorm(n) glm <- glm(y~X,family=\"gaussian\") res <- residuals.glm(glm) y_hat <- predict(glm,type=\"response\") all.equal(res,y-y_hat) #> [1] TRUE"},{"path":"/reference/sign.disc.html","id":null,"dir":"Reference","previous_headings":"","what":"Sign discovery — sign.disc","title":"Sign discovery — sign.disc","text":"Assigns signs prior weights obtain prior coefficients","code":""},{"path":"/reference/sign.disc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sign discovery — sign.disc","text":"","code":"# S3 method for disc sign(y, X, prior, family, foldid = NULL, nfolds = 10)"},{"path":"/reference/sign.disc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sign discovery — sign.disc","text":"y target: vector length \\(n\\) (see family) X features: matrix \\(n\\) rows (samples) \\(p\\) columns (features) prior prior coefficients: matrix \\(p\\) rows (features) \\(k\\) columns (sources co-data) family character \"gaussian\" (\\(y\\): real numbers), \"binomial\" (\\(y\\): 0s 1s), \"poisson\" (\\(y\\): non-negative integers); foldid fold identifiers: vector length \\(n\\) entries 1 nfolds nfolds number folds: positive integer","code":""},{"path":"/reference/sign.disc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sign discovery — sign.disc","text":"","code":"n <- 100; p <- 500 X <- matrix(stats::rnorm(n*p),nrow=n,ncol=p) beta <- stats::rnorm(p)*stats::rbinom(n=p,size=1,prob=0.2) y <- X %*% beta prior <- matrix(abs(beta),ncol=1) temp <- sign.disc(y,X,prior,family=\"gaussian\") #> Error in sign.disc(y, X, prior, family = \"gaussian\"): could not find function \"sign.disc\" table(sign(beta),sign(temp)) #> Error in table(sign(beta), sign(temp)): object 'temp' not found"},{"path":"/reference/transreg-package.html","id":null,"dir":"Reference","previous_headings":"","what":"Penalised regression with multiple sets of prior effects — transreg-package","title":"Penalised regression with multiple sets of prior effects — transreg-package","text":"R package starnet implements penalised regression multiple sets prior effects.","code":""},{"path":"/reference/transreg-package.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Penalised regression with multiple sets of prior effects — transreg-package","text":"Use function transreg model fitting. Type library(transreg) ?transreg help(\"transreg)\" open help file. See vignette examples. Type vignette(\"transreg\") browseVignettes(\"transreg\") open vignette.","code":""},{"path":"/reference/transreg-package.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Penalised regression with multiple sets of prior effects — transreg-package","text":"Armin Rauschenberger, Zied Landoulsi, Mark van de Wiel, Enrico Glaab (2022). \"Penalised regression multiple sets prior effects\". Manuscript preparation. armin.rauschenberger@uni.lu","code":""},{"path":"/reference/transreg-package.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Penalised regression with multiple sets of prior effects — transreg-package","text":"","code":"NA #> [1] NA"},{"path":"/reference/transreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Penalised regression with multiple sets of prior effects — transreg","title":"Penalised regression with multiple sets of prior effects — transreg","text":"Implements penalised regression multiple sets prior effects","code":""},{"path":"/reference/transreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Penalised regression with multiple sets of prior effects — transreg","text":"","code":"transreg(   y,   X,   prior,   family = \"gaussian\",   alpha = 1,   foldid = NULL,   nfolds = 10,   scale = \"iso\",   sign = FALSE,   switch = TRUE,   select = TRUE,   diffpen = FALSE )"},{"path":"/reference/transreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Penalised regression with multiple sets of prior effects — transreg","text":"y target: vector length \\(n\\) (see family) X features: matrix \\(n\\) rows (samples) \\(p\\) columns (features) prior prior coefficients: matrix \\(p\\) rows (features) \\(k\\) columns (sources co-data) family character \"gaussian\" (\\(y\\): real numbers), \"binomial\" (\\(y\\): 0s 1s), \"poisson\" (\\(y\\): non-negative integers); alpha elastic net mixing parameter (0=ridge, 1=lasso): number 0 1 foldid fold identifiers: vector length \\(n\\) entries 1 nfolds nfolds number folds: positive integer scale character \"exp\" exponential scaling (3 parameters), \"iso\" isotonic scaling (1+\\(p\\) parameters), \"sam\" shape-constrained additive scaling sign sign discovery procedure: logical switch choose positive negative weights source: logical select select sources: logical diffpen differential penalisation features meta-features: logical","code":""},{"path":"/reference/transreg.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Penalised regression with multiple sets of prior effects — transreg","text":"\\(n\\): sample size \\(p\\): number features \\(k\\): number sources","code":""},{"path":[]},{"path":"/reference/transreg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Penalised regression with multiple sets of prior effects — transreg","text":"","code":"n <- 100; p <- 500 X <- matrix(rnorm(n=n*p),nrow=n,ncol=p) beta <- rnorm(p)*rbinom(n=p,size=1,prob=0.2) prior <- beta # plus noise y <- X %*% beta prior <- ifelse(beta<(-1),0,ifelse(beta>1,beta,0)) plot(x=beta,y=prior)  object <- transreg(y=y,X=X,prior=prior) #> Warning: Consider sign discovery procedure. #> 7.1e-06  #> 0.54  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 4.9e-06  #> 0.051  #> + #> 6.8e-06  #> 0.41  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 2.8e-05  #> 0.71  #> + #> Warning: cannot compute exact p-value with zeroes #> 2.5e-05  #> 1  #> + #> 3.1e-05  #> 0.76  #> + #> Warning: cannot compute exact p-value with zeroes #> 1.4e-05  #> 1  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 1.2e-05  #> 0.68  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 7.8e-05  #> 0.12  #> + #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with zeroes #> 1.4e-05  #> 0.44  #> + #> 1.7e-05  #> 0.72  #> +"},{"path":"/news/index.html","id":"transreg-001-2022-08-04","dir":"Changelog","previous_headings":"","what":"transreg 0.0.1 (2022-08-04)","title":"transreg 0.0.1 (2022-08-04)","text":"first public commit","code":""}]
